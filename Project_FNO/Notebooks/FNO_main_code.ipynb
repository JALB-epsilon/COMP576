{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FNO_main_code.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMQHF8Dt/MiDf7lUHNNXG2I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xWGnZl4OneIZ"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from timeit import default_timer\n","import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l7uDbdQhneip","executionInfo":{"status":"ok","timestamp":1638568059278,"user_tz":360,"elapsed":13259,"user":{"displayName":"DM DL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04341854502427392959"}},"outputId":"66ffec35-e840-49cf-aa09-449b1ca2c1fb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"ugeuru0onf-h"},"source":["import os\n","PATH = '/content/drive/MyDrive/Parallel_PDE_project/fourier_neural_operator'\n","os.chdir(PATH)\n","import sys  \n","sys.path.insert(0, '/content/drive/MyDrive/Parallel_PDE_project/fourier_neural_operator/Notebooks')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yU7c8LMKnhoy"},"source":["from utils import *\n","from Adam import * \n","from FNO import FNO"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-8Vknytni9K"},"source":["################################################################\n","# load data and data normalization\n","################################################################\n","#EqFile = 'Burgers'\n","EqFile = 'DarcyFlow'\n","PDE_dir =  os.path.join(PATH, 'data', EqFile)\n","x_train = torch.load( os.path.join(PDE_dir, f'{EqFile}_x_train.pt'))\n","y_train = torch.load(os.path.join(PDE_dir, f'{EqFile}_y_train.pt'))\n","x_test = torch.load(os.path.join(PDE_dir, f'{EqFile}_x_test.pt'))\n","y_test= torch.load(os.path.join(PDE_dir, f'{EqFile}_y_test.pt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dx6792Zrnqbr"},"source":["#Parameters\n","ntrain = x_train.shape[0]\n","ntest = x_test.shape[0]\n","s = x_test.shape[-2]\n","batch_size = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vO1oD6JwntR7"},"source":["x_normalizer = UnitGaussianNormalizer(x_train)\n","x_train = x_normalizer.encode(x_train)\n","x_test = x_normalizer.encode(x_test)\n","\n","y_normalizer = UnitGaussianNormalizer(y_train)\n","y_train = y_normalizer.encode(y_train)\n","\n","x_train = x_train.reshape(ntrain,s,s,1)\n","#x_train = x_train.reshape(ntrain,s,1)\n","x_test = x_test.reshape(ntest,s,s,1)\n","#x_test = x_test.reshape(ntest,s,1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Roclp4X1nu_r"},"source":["train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ro77ZVH1n2NF"},"source":["# Costumized Lifting and Projection maps. \n","It can be also ignored and used the predesigned maps \n","in the files."]},{"cell_type":"code","metadata":{"id":"DC0chMHInzJc"},"source":["################################################################\n","# Lifting map\n","################################################################\n","\n","class R(nn.Module):\n","  def __init__(self, input, width):\n","    super().__init__()\n","    self.fc1 = nn.Linear(input, width)\n","  def forward(self,x):\n","    x = self.fc1(x)\n","    return x\n","\n","################################################################\n","# Projection map\n","################################################################\n","\n","class P(nn.Module):\n","  def __init__(self, width1, width2):\n","    super().__init__()\n","    self.fc1 = nn.Linear(width1, 64)\n","    self.fc2 = nn.Linear(64, 64)\n","    self.fc3 = nn.Linear(64, width2)\n","    self.nonlinear =torch.nn.functional.relu\n","  def forward(self,x):\n","    x = self.fc1(x)\n","    x = self.nonlinear(x)\n","    x = self.fc2(x)\n","    x = self.nonlinear(x)\n","    x = self.fc3(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OQatmpW6oDz1"},"source":["# FNO"]},{"cell_type":"code","metadata":{"id":"S4OxlpugnxjM"},"source":["#NN parameters\n","activ_vec = ['relu', 'tanh', 'sine', 'gelu']\n","learning_rate = 0.001\n","activ = activ_vec[0]\n","epochs = 100\n","step_size = epochs//10\n","gamma = 0.5\n","layers = 8\n","# wavenumber = [25, 25]\n","wavenumber =[20, 20]\n","features_ = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"cf9TTI8OtSfQ","executionInfo":{"status":"ok","timestamp":1638569443847,"user_tz":360,"elapsed":7,"user":{"displayName":"DM DL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04341854502427392959"}},"outputId":"277160e5-2cd6-49c4-b28f-167ace0f3fe8"},"source":["loss_train = []\n","loss_test =  []\n","epoch_vec = []\n","filename = f'FNO_problem_{EqFile}_epoch_{epochs}_wavenumber_{wavenumber}_features_{features_}_act_{activ}_layers_{layers}'\n","filename"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'FNO_problem_DarcyFlow_epoch_100_wavenumber_[20, 20]_features_32_act_relu_layers_8'"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"kaiyVfVPoDZV"},"source":["model = FNO(wavenumber = wavenumber,\n","            features_ =features_, \n","            activation = activ,\n","            layers =layers, \n","            lifting = R,\n","            proj = P).to(device)\n","# model =  torch.load(os.path.join('trained_models',filename+'.plt'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cSewjULMoSGg"},"source":["# Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qyNDVQH4oOFu","executionInfo":{"status":"ok","timestamp":1638569919062,"user_tz":360,"elapsed":469409,"user":{"displayName":"DM DL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04341854502427392959"}},"outputId":"5a128756-741a-428d-af09-ba9e1b656ed1"},"source":["print(count_params(model))\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=len(train_loader), epochs=epochs)\n","scheduler= torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","myloss = LpLoss(size_average=False)\n","y_normalizer.to(device)\n","\n","################################################################\n","# training and evaluation\n","for ep in range(epochs):\n","    model.train()\n","    t1 = default_timer()\n","    train_l2 = 0\n","    for x, y in train_loader:\n","        x, y = x.to(device), y.to(device)\n","\n","        optimizer.zero_grad()\n","        out = model(x).reshape(batch_size, s, s)\n","        #out = model(x).reshape(batch_size, s)\n","        out = y_normalizer.decode(out)\n","        y = y_normalizer.decode(y)\n","\n","        loss = myloss(out.view(batch_size,-1), y.view(batch_size,-1))\n","        loss.backward()\n","\n","        optimizer.step()\n","        train_l2 += loss.item()\n","    \n","    epoch_vec.append(ep)\n","    #e= epoch_vec[-1]\n","    #epoch_vec.append(e+1)\n","    \n","    model.eval()\n","    test_l2 = 0.0\n","    with torch.no_grad():\n","        for x, y in test_loader:\n","            x, y = x.to(device), y.to(device)\n","    \n","            out = model(x).reshape(batch_size, s, s)\n","            #out = model(x).reshape(batch_size, s)\n","            out = y_normalizer.decode(out)\n","\n","            test_l2 += myloss(out.view(batch_size,-1), y.view(batch_size,-1)).item()\n","\n","    train_l2/= ntrain\n","    test_l2 /= ntest\n","\n","    loss_train.append(train_l2)\n","    loss_test.append(test_l2)\n","\n","    t2 = default_timer()\n","    print(ep, t2-t1, train_l2, test_l2)\n","print(sum(loss_test[-5:])/5)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["6568513\n","0 4.701346278000074 0.1656050670146942 0.11375909566879272\n","1 4.68923454999981 0.1015530566573143 0.09762178599834442\n","2 4.68265253200002 0.08269901037216186 0.07816955983638764\n","3 4.677410849999887 0.06560284325480462 0.059709425270557406\n","4 4.688932884999986 0.049409393787384036 0.047282481491565706\n","5 4.69249793899985 0.03847777059674263 0.03967985302209854\n","6 4.689118606999955 0.03338325387239456 0.03544019967317581\n","7 4.6908645290000095 0.03104275654256344 0.036285606324672696\n","8 4.6811617079999905 0.028759758219122886 0.02859650954604149\n","9 4.68241299400006 0.025943032294511795 0.030839163064956664\n","10 4.685051736000105 0.02423291416466236 0.02672997459769249\n","11 4.690364655000167 0.02152752083539963 0.02570570006966591\n","12 4.684576457000048 0.02063585987687111 0.0268234720826149\n","13 4.6966224100001455 0.01972132296860218 0.025250989645719528\n","14 4.692921833000128 0.019438393130898474 0.024709376245737075\n","15 4.688525662000075 0.019723172336816787 0.02320523262023926\n","16 4.687975301000051 0.01836853069067001 0.021968958228826524\n","17 4.68867311200006 0.01853978569805622 0.022151513695716857\n","18 4.7082311019999 0.01760735447704792 0.020432656705379484\n","19 4.686133976999827 0.0174484139084816 0.022037665992975235\n","20 4.6936462670000765 0.016690825909376143 0.023678349554538725\n","21 4.681938913000067 0.020117804393172265 0.02070683181285858\n","22 4.682965342999978 0.017092286214232446 0.022122770845890045\n","23 4.687267913999904 0.015364838987588883 0.018831336349248887\n","24 4.680473885000083 0.016137345999479295 0.026971360445022585\n","25 4.694221561999939 0.018603345900774 0.021969247311353683\n","26 4.697159733000035 0.016307787038385868 0.019427570104598998\n","27 4.687646147000123 0.015113450571894645 0.019233445227146147\n","28 4.695375093999928 0.01524873785674572 0.019955262392759323\n","29 4.702352916999871 0.01483832709491253 0.01926276698708534\n","30 4.6873165870001685 0.0149775215908885 0.020256181806325914\n","31 4.6892741069998465 0.014725009433925152 0.01885600134730339\n","32 4.691287976000012 0.015226253740489483 0.018438874185085295\n","33 4.692552062000004 0.015715960942208767 0.01765670210123062\n","34 4.684022657000014 0.013927797637879848 0.017787211686372758\n","35 4.683706108000024 0.013927939794957638 0.018114469200372695\n","36 4.691197116000012 0.013450554706156253 0.016679867804050445\n","37 4.692796640000097 0.014370815590023995 0.01756320372223854\n","38 4.692399407000039 0.014331211760640145 0.016262056976556777\n","39 4.69279917599988 0.012565356813371181 0.017604835480451584\n","40 4.692958891999979 0.013109032548964023 0.0166754087805748\n","41 4.692587059000061 0.013103547908365726 0.016137567460536958\n","42 4.6878681769999275 0.013187026023864746 0.016383032351732253\n","43 4.688297076000026 0.01338854343444109 0.017444900423288345\n","44 4.696387251000033 0.013106253989040851 0.017659982144832612\n","45 4.696987130000025 0.01245136494934559 0.015635686367750166\n","46 4.72279739999999 0.013135497473180295 0.01648975342512131\n","47 4.698305520999838 0.013241776071488857 0.01741944745182991\n","48 4.689914224999939 0.012769289836287499 0.016786331087350847\n","49 4.684933817000001 0.01207657440006733 0.015544903725385665\n","50 4.690126469000006 0.013185900397598744 0.015794382616877555\n","51 4.692343593000032 0.013526522174477577 0.01611807554960251\n","52 4.705883325000059 0.014485215857625008 0.017539740651845933\n","53 4.698915657000043 0.014339653588831425 0.02543720752000809\n","54 4.689798858000131 0.01399632851779461 0.015577288940548897\n","55 4.697371464000071 0.01195961358398199 0.016171235293149948\n","56 4.699069138999903 0.011690071009099483 0.015360848978161812\n","57 4.683625455000083 0.011928257584571838 0.015306493490934372\n","58 4.686272036999981 0.013497026599943639 0.01718797639012337\n","59 4.692368882999972 0.011928032487630844 0.017866250574588776\n","60 4.693148638999901 0.01232071627676487 0.016924160867929458\n","61 4.690504029000067 0.012149397864937782 0.017094620764255525\n","62 4.687677010000016 0.012011290349066258 0.015696356296539305\n","63 4.697761279999895 0.011553681038320064 0.01524214118719101\n","64 4.694188377000046 0.01199275754392147 0.01463561825454235\n","65 4.691122032000067 0.013098237968981265 0.01628775805234909\n","66 4.690429252000058 0.011322622813284397 0.01626821905374527\n","67 4.698287422000021 0.011532317705452442 0.01675064519047737\n","68 4.694290297999942 0.011754436761140824 0.015001876950263978\n","69 4.694163607000064 0.011722172051668167 0.01429467774927616\n","70 4.693929163999883 0.011279609352350235 0.013763022348284722\n","71 4.699578800999916 0.01029268641769886 0.014741883873939514\n","72 4.689294473000018 0.010492981880903245 0.013604705929756164\n","73 4.694888009000124 0.01354926636815071 0.01566993907094002\n","74 4.696773686000142 0.012435117490589618 0.015379317253828049\n","75 4.693917802999977 0.011073899939656257 0.014209961146116256\n","76 4.688223327999822 0.011505168691277504 0.017607048451900482\n","77 4.69123692900007 0.010722084984183311 0.01346310369670391\n","78 4.697572629999968 0.011562216319143772 0.01516339898109436\n","79 4.689960223999833 0.010543473966419697 0.013913466781377792\n","80 4.694516630999942 0.011034934490919112 0.013935781642794609\n","81 4.699884373000032 0.010704141236841679 0.015999549329280854\n","82 4.704595083999948 0.014474616378545762 0.015183509811758995\n","83 4.691345413999898 0.012081315666437149 0.015525779724121093\n","84 4.69384854000009 0.011628695860505104 0.014547438845038414\n","85 4.694064735999973 0.010972401179373264 0.015000908300280572\n","86 4.684325418000071 0.010549674190580845 0.014158115983009338\n","87 4.683893448999925 0.013012840077280999 0.014180694967508315\n","88 4.693824888000108 0.01188005954027176 0.014770542159676553\n","89 4.70013994299984 0.01020466997474432 0.01653427869081497\n","90 4.687903557000027 0.010577857993543148 0.014927613511681558\n","91 4.688076305999857 0.0122062855809927 0.014960243478417396\n","92 4.6851262840000345 0.011243097260594368 0.01615312784910202\n","93 4.685534148999977 0.010897816561162472 0.012766224965453148\n","94 4.688514325999904 0.01048098199814558 0.018934603929519653\n","95 4.70369110799993 0.011899861998856068 0.014190351516008377\n","96 4.691449154000111 0.010276286825537682 0.013136559724807739\n","97 4.695250936999855 0.010163529932498932 0.015301457792520522\n","98 4.688181967999753 0.010723542250692844 0.01729888394474983\n","99 4.69035242200016 0.01091213122755289 0.013250387087464333\n","0.01463552801311016\n"]}]},{"cell_type":"code","metadata":{"id":"b_eEpVzpo2Hj"},"source":["print(f'saving model at epoch {ep}')\n","file_path = os.path.join(PATH, 'trained_models')\n","torch.save(model, os.path.join(file_path, filename+'.plt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1c_I-X-6oXBP"},"source":["  fig, axs = plt.subplots(2, 1, figsize=(17,17))\n","  axs[0].plot(epoch_vec, loss_train)\n","  axs[0].set_title(f'Training loss {filename}')\n","  axs[0].set_yscale('log')\n","  axs[1].plot(epoch_vec, loss_test, 'tab:orange')\n","  axs[1].set_title('Test loss')\n","  axs[1].set_yscale('log')\n","  plt.savefig(os.path.join(PATH, 'figures', filename+'.png'))"],"execution_count":null,"outputs":[]}]}