{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ExperimentsFNOsAntonio.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMk3XtwPf2nqd6yQY/PEt2p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Vrpb4kO1qS3O","executionInfo":{"status":"ok","timestamp":1637992908270,"user_tz":360,"elapsed":5861,"user":{"displayName":"DM DL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04341854502427392959"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from timeit import default_timer\n","import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hEfaqkDL-y9d"},"source":["#SOBOLEV NORM"]},{"cell_type":"code","metadata":{"id":"o169nfs9-2VV","executionInfo":{"status":"ok","timestamp":1637993094688,"user_tz":360,"elapsed":166,"user":{"displayName":"DM DL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04341854502427392959"}}},"source":["# Sobolev norm (HS norm)\n","# where we also compare the numerical derivatives between the output and target\n","class HsLoss(object):\n","    def __init__(self, d=2, p=2, k=1, a=None, group=False, size_average=True, reduction=True):\n","        super(HsLoss, self).__init__()\n","\n","        #Dimension and Lp-norm type are postive\n","        assert d > 0 and p > 0\n","\n","        self.d = d\n","        self.p = p\n","        self.k = k\n","        self.balanced = group\n","        self.reduction = reduction\n","        self.size_average = size_average\n","\n","        if a == None:\n","            a = [1,] * k\n","        self.a = a\n","\n","    def rel(self, x, y):\n","        num_examples = x.size()[0]\n","        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n","        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n","        if self.reduction:\n","            if self.size_average:\n","                return torch.mean(diff_norms/y_norms)\n","            else:\n","                return torch.sum(diff_norms/y_norms)\n","        return diff_norms/y_norms\n","\n","    def __call__(self, x, y, a=None):\n","        nx = x.size()[1]\n","        ny = x.size()[2]\n","        k = self.k\n","        balanced = self.balanced\n","        a = self.a\n","        x = x.view(x.shape[0], nx, ny, -1)\n","        y = y.view(y.shape[0], nx, ny, -1)\n","\n","        k_x = torch.cat((torch.arange(start=0, end=nx//2, step=1),\n","                         torch.arange(start=-nx//2, end=0, step=1)), 0).reshape(nx,1).repeat(1,ny)\n","        k_y = torch.cat((torch.arange(start=0, end=ny//2, step=1),\n","                         torch.arange(start=-ny//2, end=0, step=1)), 0).reshape(1,ny).repeat(nx,1)\n","        k_x = torch.abs(k_x).reshape(1,nx,ny,1).to(x.device)\n","        k_y = torch.abs(k_y).reshape(1,nx,ny,1).to(x.device)\n","\n","        x = torch.fft.fftn(x, dim=[1, 2])\n","        y = torch.fft.fftn(y, dim=[1, 2])\n","\n","        if balanced==False:\n","            weight = 1\n","            if k >= 1:\n","                weight += a[0]**2 * (k_x**2 + k_y**2)\n","            if k >= 2:\n","                weight += a[1]**2 * (k_x**4 + 2*k_x**2*k_y**2 + k_y**4)\n","            weight = torch.sqrt(weight)\n","            loss = self.rel(x*weight, y*weight)\n","        else:\n","            loss = self.rel(x, y)\n","            if k >= 1:\n","                weight = a[0] * torch.sqrt(k_x**2 + k_y**2)\n","                loss += self.rel(x*weight, y*weight)\n","            if k >= 2:\n","                weight = a[1] * torch.sqrt(k_x**4 + 2*k_x**2*k_y**2 + k_y**4)\n","                loss += self.rel(x*weight, y*weight)\n","            loss = loss / (k+1)\n","\n","        return loss\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"fA-Q10ys_uSs","executionInfo":{"status":"ok","timestamp":1637993178153,"user_tz":360,"elapsed":289,"user":{"displayName":"DM DL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04341854502427392959"}}},"source":["x = torch.randn(20,32,128,128)\n","y = torch.randn(20,32,128,128)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"0d-I3Xx3AHUG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XphdYNKvpNUg","executionInfo":{"status":"ok","timestamp":1637988420525,"user_tz":360,"elapsed":30334,"user":{"displayName":"DM DL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04341854502427392959"}},"outputId":"3712f7fd-3603-4f42-d148-d6208d75a926"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"Wx4LK3lppgtR"},"source":["import os\n","PATH = '/content/drive/MyDrive/Parallel_PDE_project/fourier_neural_operator'\n","os.chdir(PATH)\n","import sys  \n","sys.path.insert(0, '/content/drive/MyDrive/Parallel_PDE_project/fourier_neural_operator/Notebooks')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-TQty4x9phVq"},"source":["from utils import *\n","from Adam import * \n","from FNO import Lifting, Proj, set_activ"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvfbbqJX40sR"},"source":["def anderson(f, x0, m=5, lam=1e-4, max_iter=50, tol=1e-2, beta = 1.0):\n","    \"\"\" Anderson acceleration for fixed point iteration. \"\"\"\n","    bsz, d, H, W = x0.shape\n","    X = torch.zeros(bsz, m, d*H*W, dtype=x0.dtype, device=x0.device)\n","    F = torch.zeros(bsz, m, d*H*W, dtype=x0.dtype, device=x0.device)\n","    X[:,0], F[:,0] = x0.reshape(bsz, -1), f(x0).view(bsz, -1)\n","    X[:,1], F[:,1] = F[:,0], f(F[:,0].view_as(x0)).view(bsz, -1)\n","    \n","    H = torch.zeros(bsz, m+1, m+1, dtype=x0.dtype, device=x0.device)\n","    H[:,0,1:] = H[:,1:,0] = 1\n","    y = torch.zeros(bsz, m+1, 1, dtype=x0.dtype, device=x0.device)\n","    y[:,0] = 1\n","    \n","    res = []\n","    for k in range(2, max_iter):\n","        n = min(k, m)\n","        G = F[:,:n]-X[:,:n]\n","        H[:,1:n+1,1:n+1] = torch.bmm(G,G.transpose(1,2)) + lam*torch.eye(n, dtype=x0.dtype,device=x0.device)[None]\n","        alpha = torch.solve(y[:,:n+1], H[:,:n+1,:n+1])[0][:, 1:n+1, 0]   # (bsz x n)\n","        \n","        X[:,k%m] = beta * (alpha[:,None] @ F[:,:n])[:,0] + (1-beta)*(alpha[:,None] @ X[:,:n])[:,0]\n","        F[:,k%m] = f(X[:,k%m].view_as(x0)).view(bsz, -1)\n","        res.append((F[:,k%m] - X[:,k%m]).norm().item()/(1e-5 + F[:,k%m].norm().item()))\n","        if (res[-1] < tol):\n","            break\n","    return X[:,k%m].view_as(x0), res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Orc9vClY6z-M"},"source":["import torch.autograd as autograd\n","\n","class DEQFixedPoint(nn.Module):\n","    def __init__(self, f, solver, **kwargs):\n","        super().__init__()\n","        self.f = f\n","        self.solver = solver\n","        self.kwargs = kwargs\n","        \n","    def forward(self, x):\n","        # compute forward pass and re-engage autograd tape\n","        with torch.no_grad():\n","            z, self.forward_res = self.solver(lambda z : self.f(z, x), torch.zeros_like(x), **self.kwargs)\n","        z = self.f(z,x)\n","        \n","        # set up Jacobian vector product (without additional forward calls)\n","        z0 = z.clone().detach().requires_grad_()\n","        f0 = self.f(z0,x)\n","        def backward_hook(grad):\n","            g, self.backward_res = self.solver(lambda y : autograd.grad(f0, z0, y, retain_graph=True)[0] + grad,\n","                                               grad, **self.kwargs)\n","            return g\n","                \n","        z.register_hook(backward_hook)\n","        return z"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k8WE4U0LuQ14"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"w4ujxvcGuRFG"},"source":[""]},{"cell_type":"code","metadata":{"id":"5ceNOsYUuO0X"},"source":["################################################################\n","# Spectral Convolution Layers \n","# 1D and 2D\n","################################################################\n","\n","class fourier_conv_1d(nn.Module):\n","  def __init__(self, in_, out_, wavenumber1):\n","    super(fourier_conv_1d, self).__init__()\n","    self.in_ = in_\n","    self.out_ = out_\n","    self.wavenumber1 = wavenumber1\n","    self.scale = (1 / (in_ * out_))\n","    self.weights1 = nn.Parameter(self.scale * torch.rand(in_, out_, self.wavenumber1, dtype= torch.complex128))\n","   \n","    # Complex multiplication\n","  def compl_mul1d(self, input, weights):\n","    # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n","    return torch.einsum(\"bix,iox->box\", input, weights)\n","\n","  def forward(self, x):\n","    batchsize = x.shape[0]\n","    #Compute Fourier coeffcients up to factor of e^(- something constant)\n","    x_ft = torch.fft.rfft(x)\n","\n","    # Multiply relevant Fourier modes\n","    out_ft = torch.zeros(batchsize, self.out_, x.size(-1)//2 + 1,  device=x.device, dtype= torch.complex128)\n","    out_ft[:, :, :self.wavenumber1] = self.compl_mul1d(x_ft[:, :, :self.wavenumber1], self.weights1)\n","\n","    #Return to physical space\n","    x = torch.fft.irfft(out_ft, n=x.size(-1))\n","    return x\n","\n","  def print(self):\n","    return f'FourierConv1d({self.in_}, {self.out_}, wavenumber={self.wavenumber1})'\n","\n","class fourier_conv_2d(nn.Module):\n","  def __init__(self, in_, out_, wavenumber1, wavenumber2):\n","    super(fourier_conv_2d, self).__init__()\n","    self.in_ = in_\n","    self.out_ = out_\n","    self.wavenumber1 = wavenumber1\n","    self.wavenumber2 = wavenumber2\n","    self.scale = (1 / (in_ * out_))\n","    self.weights1 = nn.Parameter(self.scale * torch.rand(in_, out_, self.wavenumber1, self.wavenumber2, dtype= torch.complex128))\n","    self.weights2 = nn.Parameter(self.scale * torch.rand(in_, out_, self.wavenumber1, self.wavenumber2, dtype= torch.complex128))\n","\n","    # Complex multiplication\n","  def compl_mul2d(self, input, weights):\n","    # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n","    return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n","\n","  def forward(self, x):\n","    batchsize = x.shape[0]\n","    #Compute Fourier coeffcients up to factor of e^(- something constant)\n","    x_ft = torch.fft.rfft2(x)\n","    # Multiply relevant Fourier modes\n","    out_ft = torch.zeros(batchsize, self.in_,  x.size(-2), x.size(-1)//2 + 1, dtype= torch.complex128, device=x.device)\n","    out_ft[:, :, :self.wavenumber1, :self.wavenumber2] = \\\n","        self.compl_mul2d(x_ft[:, :, :self.wavenumber1, :self.wavenumber2], self.weights1)\n","    out_ft[:, :, -self.wavenumber1:, :self.wavenumber2] = \\\n","        self.compl_mul2d(x_ft[:, :, -self.wavenumber1:, :self.wavenumber2], self.weights2)\n","    #Return to physical space\n","    x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n","    return x\n","\n","  def print(self):\n","    return f'FourierConv2d({self.in_}, {self.out_}, wavenumber={self.wavenumber1, self.wavenumber2})'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LlPuSDN2uzDj"},"source":["################################################################\n","# Fourier Layer \n","################################################################\n","class Fourier_layer(nn.Module):\n","  def __init__(self,  features_, wavenumber, activation = 'relu', is_last = False):\n","    super(Fourier_layer, self).__init__()\n","    self.is_last = is_last\n","    self.activation = activation.lower()\n","    self.features_ = features_\n","    self.wavenumber = wavenumber\n","    self.dim = len(wavenumber)\n","    self.W =  nn.Conv1d(features_, features_, 1).double() if self.dim==1 else nn.Conv2d(features_, features_, 1).double()\n","    self.fourier_conv = self.set_conv_dim()\n","    self.nonlinear = set_activ(activation)\n","\n","  def set_conv_dim(self):\n","    if self.dim== 1:\n","      return  fourier_conv_1d(self.features_, self.features_, *self.wavenumber)\n","    elif self.dim== 2:\n","      return  fourier_conv_2d(self.features_, self.features_, *self.wavenumber)\n","   \n","  def forward(self, x):\n","        x1 = self.fourier_conv(x)\n","        x2 = self.W(x)\n","        x = x1 + x2\n","        if self.is_last == True:\n","          return x\n","        else:\n","          x = self.nonlinear(x)\n","          return x\n","            \n","  def __repr__(self):\n","    with torch.no_grad():\n","      return self.activation+'('+self.fourier_conv.print() +' + '+ self.W.__repr__()+')'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNGG17ZZu40p"},"source":["class ResNetLayerFourier(nn.Module):\n","    def __init__(self, features_, wavenumber, activation = 'relu'):\n","        super(ResNetLayerFourier, self).__init__()\n","        self.dim = len(wavenumber)\n","        self.activation = activation.lower()\n","        self.FourierLayer = Fourier_layer(features_, wavenumber, activation = self.activation)\n","        self.nonlinear = set_activ(activation)\n","        self.W =nn.Conv1d(features_, features_, 1).double() if self.dim==1 else nn.Conv2d(features_, features_, 1).double()\n","    def forward(self, z, x):\n","        return self.nonlinear(self.W(x) +self.FourierLayer(z))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AI01lbiAiM3E"},"source":["from torch.autograd import gradcheck\n","# run a very small network with double precision, iterating to high precision\n","f = ResNetLayerFourier(32,[12,12]).double()\n","deq = DEQFixedPoint(f, anderson, tol=1e-5, max_iter=10).double()\n","gradcheck(deq, torch.randn(1,32,64,64).double().requires_grad_(), eps=1e-5, atol=1e-3, check_undefined_grad=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"biJIDXeSIDql"},"source":["################################################################\n","# Lifting map\n","################################################################\n","\n","class Lifting(nn.Module):\n","  def __init__(self, input, width, activation = 'relu'):\n","    super().__init__()\n","    self.fc1 = nn.Linear(input, width//2)\n","    self.nonlinear =set_activ(activation)\n","    self.fc2 = nn.Linear(width//2, width)\n","  def forward(self,x):\n","    x = self.fc1(x)\n","    x = self.nonlinear(x)\n","    x = self.fc2(x)\n","    return x\n","\n","################################################################\n","# Projection map\n","################################################################\n","\n","class Proj(nn.Module):\n","  def __init__(self,width1, width2=1, activation = 'relu'):\n","    super().__init__()\n","    self.fc1 = nn.Linear(width1, 128)\n","    self.fc2 = nn.Linear(128, width2)\n","    self.nonlinear =set_activ(activation)\n","  def forward(self,x):\n","    x = self.fc1(x)\n","    x = self.nonlinear(x)\n","    x = self.fc2(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KBhqDgqF31T_"},"source":["################################################################\n","# FNO_DEQ map 1D and 2D\n","################################################################\n","\n","class FNO_DEQ(nn.Module):\n","  def __init__(self, wavenumber, features_, \n","                    padding = 9, \n","                    activation= 'relu',\n","                    lifting = Lifting, \n","                    proj = Proj, \n","                    max_iter=100, \n","                    beta=2.0):\n","    super(FNO_DEQ, self).__init__()\n","    self.wavenumber = wavenumber\n","    self.dim = len(wavenumber)\n","    self.activation = activation.lower() \n","    self.padding = padding   \n","    self.features_ =features_\n","    self.lifting = lifting(self.dim+1, self.features_)\n","    self.fno = ResNetLayerFourier(features_ = self.features_, \n","                                  wavenumber=self.wavenumber, \n","                                  activation = self.activation)\n","    self.deq = DEQFixedPoint(self.fno, anderson, tol=1e-4, max_iter=max_iter, beta=beta)\n","    self.proj = proj(self.features_, 1)\n","    \n","  def forward(self, x):\n","    grid = self.get_grid2D(x.shape, x.device) if self.dim == 2 else self.get_grid1D(x.shape, x.device)\n","    x = torch.cat((x, grid), dim=-1)\n","    ####Lifting Map \n","    x = self.lifting(x)\n","    ###Actual Neural Operator\n","    x = x.permute(0, 3, 1, 2) if self.dim == 2 else x.permute(0, 2, 1)\n","    x = F.pad(x, [0,self.padding, 0,self.padding]) if self.dim == 2 else F.pad(x, [0,self.padding])\n","    x = self.deq(x)\n","    x = x[..., :-self.padding, :-self.padding] if self.dim == 2 else x[..., :-self.padding]\n","    x = x.permute(0, 2, 3, 1) if self.dim == 2 else x.permute(0, 2, 1)\n","    ####Projection Map\n","    x =self.proj(x)\n","    return x\n","    \n","  def get_grid2D(self, shape, device):\n","    batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n","    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n","    gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n","    gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n","    gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n","    return torch.cat((gridx, gridy), dim=-1).to(device)\n","\n","  def get_grid1D(self, shape, device):\n","    batchsize, size_x = shape[0], shape[1]\n","    gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n","    gridx = gridx.reshape(1, size_x, 1).repeat([batchsize, 1, 1])\n","    return gridx.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NuiZV9jCuPGY"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"5Kahu5UUuPJ_"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"g3sgmj2quPNo"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"DMycPASZuPQq"},"source":[""]},{"cell_type":"code","metadata":{"id":"xD87lZGFPbUH"},"source":["################################################################\n","# load data and data normalization\n","################################################################\n","EqFile = 'DarcyFlow'\n","PDE_dir =  os.path.join(PATH, 'data', EqFile)\n","x_train = torch.load( os.path.join(PDE_dir, f'{EqFile}_x_train.pt')).double()\n","y_train = torch.load(os.path.join(PDE_dir, f'{EqFile}_y_train.pt')).double()\n","x_test = torch.load(os.path.join(PDE_dir, f'{EqFile}_x_test.pt')).double()\n","y_test= torch.load(os.path.join(PDE_dir, f'{EqFile}_y_test.pt')).double()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kofxjjpWpmdR"},"source":["#Parameters\n","ntrain = x_train.shape[0]\n","ntest = x_test.shape[0]\n","s = x_test.shape[-2]\n","batch_size = 20"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j_HyNIP7pplC"},"source":["x_normalizer = UnitGaussianNormalizer(x_train)\n","x_train = x_normalizer.encode(x_train)\n","x_test = x_normalizer.encode(x_test)\n","\n","y_normalizer = UnitGaussianNormalizer(y_train)\n","y_train = y_normalizer.encode(y_train)\n","\n","x_train = x_train.reshape(ntrain,s,s,1)\n","#x_train = x_train.reshape(ntrain,s,1)\n","x_test = x_test.reshape(ntest,s,s,1)\n","#x_test = x_test.reshape(ntest,s,1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TsbKiYxwceaf"},"source":["train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaobiYycpt5j"},"source":["loss_train = []\n","loss_test =  []\n","epoch_vec = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1r9cav4vpyBq"},"source":["#NN parameters\n","activ_vec = ['relu', 'tanh', 'sine', 'gelu']\n","activ = activ_vec[0]\n","layers = 5\n","learning_rate = 0.001\n","\n","epochs = 100\n","step_size = epochs//5\n","gamma = 0.5\n","\n","wavenumber = [12, 12]\n","features_ = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JpUKdWspMR4R","executionInfo":{"status":"ok","timestamp":1637987703492,"user_tz":360,"elapsed":3212,"user":{"displayName":"DM DL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04341854502427392959"}},"outputId":"98e5b765-167a-4c90-dea0-85bffd26f8cb"},"source":["model = FNO_DEQ(wavenumber = wavenumber,\n","            features_ =features_, \n","            activation = 'relu', \n","            lifting = Lifting,\n","            proj = Proj,\n","            max_iter = 10).double().to(device)\n","model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FNO_DEQ(\n","  (lifting): Lifting(\n","    (fc1): Linear(in_features=3, out_features=16, bias=True)\n","    (fc2): Linear(in_features=16, out_features=32, bias=True)\n","  )\n","  (fno): ResNetLayerFourier(\n","    (FourierLayer): relu(FourierConv2d(32, 32, wavenumber=(12, 12)) + Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1)))\n","    (W): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (deq): DEQFixedPoint(\n","    (f): ResNetLayerFourier(\n","      (FourierLayer): relu(FourierConv2d(32, 32, wavenumber=(12, 12)) + Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1)))\n","      (W): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (proj): Proj(\n","    (fc1): Linear(in_features=32, out_features=128, bias=True)\n","    (fc2): Linear(in_features=128, out_features=1, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"id":"C_Qb6eXcqIz8","executionInfo":{"status":"error","timestamp":1637987724553,"user_tz":360,"elapsed":15581,"user":{"displayName":"DM DL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04341854502427392959"}},"outputId":"f7fd48b8-0860-4ac4-cfae-638eef39e511"},"source":["print(count_params(model))\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n","#scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=len(train_loader), epochs=epochs)\n","scheduler= torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","myloss = LpLoss(size_average=False)\n","y_normalizer.to(device)\n","\n","################################################################\n","# training and evaluation\n","for ep in range(epochs//2):\n","    model.train()\n","    t1 = default_timer()\n","    train_l2 = 0\n","    for x, y in train_loader:\n","        x, y = x.double().to(device), y.double().to(device)\n","\n","        optimizer.zero_grad()\n","        out = model(x).reshape(batch_size, s, s)\n","        #out = model(x).reshape(batch_size, s)\n","        out = y_normalizer.decode(out)\n","        y = y_normalizer.decode(y)\n","\n","        loss = myloss(out.view(batch_size,-1), y.view(batch_size,-1))\n","        loss.backward()\n","\n","        optimizer.step()\n","        train_l2 += loss.item()\n","    \n","    epoch_vec.append(ep)\n","    #e= epoch_vec[-1]\n","    #epoch_vec.append(e+1)\n","    \n","    model.eval()\n","    test_l2 = 0.0\n","    with torch.no_grad():\n","        for x, y in test_loader:\n","            x, y = x.double().to(device), y.double().to(device)\n","    \n","            out = model(x).reshape(batch_size, s, s)\n","            #out = model(x).reshape(batch_size, s)\n","            out = y_normalizer.decode(out)\n","\n","            test_l2 += myloss(out.view(batch_size,-1), y.view(batch_size,-1)).item()\n","\n","    train_l2/= ntrain\n","    test_l2 /= ntest\n","\n","    loss_train.append(train_l2)\n","    loss_test.append(test_l2)\n","\n","    t2 = default_timer()\n","    print(ep, t2-t1, train_l2, test_l2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["301985\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-17c4de7daf31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;31m#out = model(x).reshape(batch_size, s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_normalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-d54ae1d7c257>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-a6fe47029ee7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackward_hook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mregister_hook\u001b[0;34m(self, hook)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             raise RuntimeError(\"cannot register a hook on a tensor that \"\n\u001b[0m\u001b[1;32m    342\u001b[0m                                \"doesn't require gradient\")\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: cannot register a hook on a tensor that doesn't require gradient"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YGJ8p-DRhkmg","executionInfo":{"status":"ok","timestamp":1637985243551,"user_tz":360,"elapsed":366,"user":{"displayName":"DM DL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04341854502427392959"}},"outputId":"593e175b-ba01-4447-9e79-105ba9ffaff0"},"source":["model.double()(x)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n","torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n","To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n","X = torch.solve(B, A).solution\n","should be replaced with\n","X = torch.linalg.solve(A, B) (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:766.)\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[[[0.0463],\n","          [0.0460],\n","          [0.0458],\n","          ...,\n","          [0.0837],\n","          [0.0839],\n","          [0.0838]],\n","\n","         [[0.0463],\n","          [0.0462],\n","          [0.0461],\n","          ...,\n","          [0.0845],\n","          [0.0842],\n","          [0.0843]],\n","\n","         [[0.0465],\n","          [0.0463],\n","          [0.0462],\n","          ...,\n","          [0.0852],\n","          [0.0850],\n","          [0.0849]],\n","\n","         ...,\n","\n","         [[0.1050],\n","          [0.1052],\n","          [0.1052],\n","          ...,\n","          [0.0554],\n","          [0.0555],\n","          [0.0553]],\n","\n","         [[0.1051],\n","          [0.1053],\n","          [0.1055],\n","          ...,\n","          [0.0558],\n","          [0.0555],\n","          [0.0555]],\n","\n","         [[0.1052],\n","          [0.1053],\n","          [0.1055],\n","          ...,\n","          [0.0556],\n","          [0.0556],\n","          [0.0557]]],\n","\n","\n","        [[[0.0463],\n","          [0.0460],\n","          [0.0458],\n","          ...,\n","          [0.0458],\n","          [0.0458],\n","          [0.0458]],\n","\n","         [[0.0464],\n","          [0.0462],\n","          [0.0461],\n","          ...,\n","          [0.0459],\n","          [0.0459],\n","          [0.0459]],\n","\n","         [[0.0465],\n","          [0.0463],\n","          [0.0462],\n","          ...,\n","          [0.0459],\n","          [0.0459],\n","          [0.0459]],\n","\n","         ...,\n","\n","         [[0.1049],\n","          [0.1051],\n","          [0.1051],\n","          ...,\n","          [0.0555],\n","          [0.0555],\n","          [0.0553]],\n","\n","         [[0.1051],\n","          [0.1052],\n","          [0.1054],\n","          ...,\n","          [0.0558],\n","          [0.0556],\n","          [0.0556]],\n","\n","         [[0.1052],\n","          [0.1053],\n","          [0.1055],\n","          ...,\n","          [0.0557],\n","          [0.0557],\n","          [0.0558]]],\n","\n","\n","        [[[0.0840],\n","          [0.0846],\n","          [0.0849],\n","          ...,\n","          [0.0457],\n","          [0.0458],\n","          [0.0458]],\n","\n","         [[0.0849],\n","          [0.0851],\n","          [0.0852],\n","          ...,\n","          [0.0459],\n","          [0.0459],\n","          [0.0459]],\n","\n","         [[0.0854],\n","          [0.0857],\n","          [0.0856],\n","          ...,\n","          [0.0459],\n","          [0.0459],\n","          [0.0459]],\n","\n","         ...,\n","\n","         [[0.1050],\n","          [0.1052],\n","          [0.1052],\n","          ...,\n","          [0.0555],\n","          [0.0555],\n","          [0.0553]],\n","\n","         [[0.1051],\n","          [0.1053],\n","          [0.1055],\n","          ...,\n","          [0.0558],\n","          [0.0556],\n","          [0.0556]],\n","\n","         [[0.1052],\n","          [0.1053],\n","          [0.1055],\n","          ...,\n","          [0.0557],\n","          [0.0557],\n","          [0.0558]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0.0463],\n","          [0.0460],\n","          [0.0458],\n","          ...,\n","          [0.0838],\n","          [0.0839],\n","          [0.0838]],\n","\n","         [[0.0464],\n","          [0.0462],\n","          [0.0461],\n","          ...,\n","          [0.0845],\n","          [0.0843],\n","          [0.0844]],\n","\n","         [[0.0465],\n","          [0.0463],\n","          [0.0462],\n","          ...,\n","          [0.0853],\n","          [0.0850],\n","          [0.0849]],\n","\n","         ...,\n","\n","         [[0.0591],\n","          [0.0588],\n","          [0.0587],\n","          ...,\n","          [0.0555],\n","          [0.0555],\n","          [0.0553]],\n","\n","         [[0.0592],\n","          [0.0590],\n","          [0.0587],\n","          ...,\n","          [0.0558],\n","          [0.0556],\n","          [0.0556]],\n","\n","         [[0.0594],\n","          [0.0591],\n","          [0.0589],\n","          ...,\n","          [0.0557],\n","          [0.0557],\n","          [0.0558]]],\n","\n","\n","        [[[0.0840],\n","          [0.0846],\n","          [0.0849],\n","          ...,\n","          [0.0838],\n","          [0.0839],\n","          [0.0838]],\n","\n","         [[0.0849],\n","          [0.0851],\n","          [0.0852],\n","          ...,\n","          [0.0845],\n","          [0.0843],\n","          [0.0844]],\n","\n","         [[0.0854],\n","          [0.0856],\n","          [0.0856],\n","          ...,\n","          [0.0853],\n","          [0.0850],\n","          [0.0849]],\n","\n","         ...,\n","\n","         [[0.0591],\n","          [0.0588],\n","          [0.0587],\n","          ...,\n","          [0.1158],\n","          [0.1159],\n","          [0.1155]],\n","\n","         [[0.0592],\n","          [0.0589],\n","          [0.0587],\n","          ...,\n","          [0.1163],\n","          [0.1160],\n","          [0.1160]],\n","\n","         [[0.0593],\n","          [0.0591],\n","          [0.0589],\n","          ...,\n","          [0.1161],\n","          [0.1162],\n","          [0.1164]]],\n","\n","\n","        [[[0.0840],\n","          [0.0846],\n","          [0.0849],\n","          ...,\n","          [0.0838],\n","          [0.0839],\n","          [0.0838]],\n","\n","         [[0.0849],\n","          [0.0850],\n","          [0.0852],\n","          ...,\n","          [0.0845],\n","          [0.0843],\n","          [0.0844]],\n","\n","         [[0.0854],\n","          [0.0856],\n","          [0.0856],\n","          ...,\n","          [0.0853],\n","          [0.0850],\n","          [0.0849]],\n","\n","         ...,\n","\n","         [[0.1049],\n","          [0.1051],\n","          [0.1052],\n","          ...,\n","          [0.0555],\n","          [0.0555],\n","          [0.0553]],\n","\n","         [[0.1051],\n","          [0.1053],\n","          [0.1055],\n","          ...,\n","          [0.0558],\n","          [0.0555],\n","          [0.0555]],\n","\n","         [[0.1052],\n","          [0.1053],\n","          [0.1055],\n","          ...,\n","          [0.0557],\n","          [0.0556],\n","          [0.0557]]]], device='cuda:0', dtype=torch.float64,\n","       grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"P5uxAn4xmDTy"},"source":["x.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5cJvDnN9Rvq7"},"source":["grid = model.get_grid(x.shape, x.device)\n","grid.shape\n","#x = torch.cat((x, grid), dim=-1)\n","#x =model.lifting(x)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s-mHVSfmlsA6"},"source":["grid.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vuv1zn1KlMuO"},"source":["x.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WW-u02HqAIkU"},"source":["    ####Lifting Map \n","    x = self.lifting(x)\n","    ###Actual Neural Operator\n","    x = x.permute(0, 3, 1, 2) if self.dim == 2 else x.permute(0, 2, 1)\n","    x = F.pad(x, [0,self.padding, 0,self.padding]) if self.dim == 2 else F.pad(x, [0,self.padding])\n","    x = self.fno(x)\n","    x = x[..., :-self.padding, :-self.padding] if self.dim == 2 else x[..., :-self.padding]\n","    x = x.permute(0, 2, 3, 1) if self.dim == 2 else x.permute(0, 2, 1)\n","    ####Projection Map\n","    x =self.proj(x)"],"execution_count":null,"outputs":[]}]}